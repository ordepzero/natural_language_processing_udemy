{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl  https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt -O robert_frost.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    return s.translate(str.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = {} # start of a phrase\n",
    "first_order = {} # second word only\n",
    "second_order = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add2dict(d, k, v):\n",
    "    if k not in d:\n",
    "        d[k] = []\n",
    "    \n",
    "    d[k].append(v)\n",
    "\n",
    "# [cat, cat, dog, dog, dog, dog, dog, mouse, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in open('robert_frost.txt'):\n",
    "    tokens = remove_punctuation(line.rstrip().lower()).split()\n",
    "\n",
    "    T = len(tokens)\n",
    "    \n",
    "    #print(line)\n",
    "    \n",
    "    for i in range(T):\n",
    "        #print(second_order)\n",
    "        t = tokens[i]\n",
    "        \n",
    "        if i == 0:\n",
    "            # measure the distribution of the first word\n",
    "            initial[t] = initial.get(t, 0.) + 1\n",
    "        else:\n",
    "            t_1 = tokens[i-1]\n",
    "            \n",
    "            if i == T - 1:\n",
    "                # measure probability of ending the line\n",
    "                # add2dict(second_order, (t_1, t), 'END')\n",
    "                if (t_1, t) not in second_order:\n",
    "                    second_order[(t_1, t)] = {'END':1}\n",
    "                else:\n",
    "                    second_order[(t_1, t)]['END'] = second_order[(t_1, t)].get('END',0) + 1\n",
    "            if i == 1:\n",
    "                # measure distribution of second word\n",
    "                # given only first word\n",
    "                # add2dict(first_order, t_1, t)\n",
    "                if t_1 not in first_order:\n",
    "                    first_order[t_1] = {t: 1}\n",
    "                else:\n",
    "                    first_order[t_1][t] = first_order[t_1].get(t,0) + 1\n",
    "            else:\n",
    "                t_2 = tokens[i-2]\n",
    "                # add2dict(second_order, (t_2, t_1), t)\n",
    "                if (t_2, t_1) not in second_order:\n",
    "                    second_order[(t_2, t_1)] = {t: 1}\n",
    "                else:\n",
    "                    second_order[(t_2, t_1)][t] = second_order[(t_2, t_1)].get(t,0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the distributions\n",
    "initial_total = sum(initial.values())\n",
    "for t, c in initial.items():\n",
    "    initial[t] = c / initial_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert [cat, cat, cat, dog, dog, dog, dog, mouse, ...]\n",
    "# into {cat: 0.5, dog: 0.4, mouse: 0.1}\n",
    "\n",
    "def list2pdict(ts):\n",
    "    # turn each list of possibilities into a dictionary of probabilities\n",
    "    d = {}\n",
    "    n = len(ts)\n",
    "    for t in ts:\n",
    "        d[t] = d.get(t, 0.) + 1\n",
    "    for t, c in d.items():\n",
    "        d[t] = c / n\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert [cat, cat, cat, dog, dog, dog, dog, mouse, ...]\n",
    "# into {cat: 0.5, dog: 0.4, mouse: 0.1}\n",
    "\n",
    "def list2prob_dict(ts):\n",
    "    # turn each list of possibilities into a dictionary of probabilities\n",
    "    d = {}\n",
    "    n = 0\n",
    "    for t, c in ts.items():\n",
    "        n += c\n",
    "    for t, c in ts.items():\n",
    "        d[t] = c / n\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t_1, ts in first_order.items():\n",
    "    # replace list with dictionary of probabilities\n",
    "    first_order[t_1] = list2prob_dict(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, ts in second_order.items():\n",
    "    second_order[k] = list2prob_dict(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_word(d):\n",
    "    \n",
    "    # print \"d:\", d\n",
    "    p0 = np.random.random()\n",
    "    # print \"p0:\", p0\n",
    "    cumulative = 0\n",
    "    \n",
    "    for t, p in d.items():\n",
    "        cumulative += p\n",
    "        if p0 < cumulative:\n",
    "            return t\n",
    "    assert(False) # should never get here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    for i in range(4): # generate 4 lines\n",
    "        sentence = []\n",
    "\n",
    "        # initial word\n",
    "        w0 = sample_word(initial)\n",
    "        sentence.append(w0)\n",
    "\n",
    "        # sample second word\n",
    "        w1 = sample_word(first_order[w0])\n",
    "        sentence.append(w1)\n",
    "\n",
    "        # second-order transitions until END\n",
    "        while True:\n",
    "            w2 = sample_word(second_order[(w0, w1)])\n",
    "            if w2 == 'END':\n",
    "                break\n",
    "            sentence.append(w2)\n",
    "            w0 = w1\n",
    "            w1 = w2\n",
    "            \n",
    "        print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i went to bed alone and left me\n",
      "might just as empty\n",
      "but it isnt as if and thats not all the money goes so fast\n",
      "you couldnt call it living for it aint\n"
     ]
    }
   ],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2:\n",
    "# We can skip the step where we accumulate all the possible next words in a list\n",
    "# E.g. [cat, cat, dog, dog, dog, ...]\n",
    "#\n",
    "# Instead, like we do with the initial state distribution, create the dictionary\n",
    "# of counts directly as you loop through the data.\n",
    "#\n",
    "# You'll no longer need list2pdict()\n",
    "# Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
