{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a markov model based on an English dataset\n",
    "# is an edit of https://www.gutenberg.org/ebooks/2701\n",
    "# (I removed the front and back matter)\n",
    "\n",
    "# download the file\n",
    "if not os.path.exists('moby_dick.txt'):\n",
    "    print(\"Downloading moby dick...\")\n",
    "    r = requests.get('https://lazyprogrammer.me/course_files/moby_dick.txt')\n",
    "    with open('moby_dick.txt', 'w',encoding='utf-8') as f:\n",
    "        f.write(r.content.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('moby_dick.txt',encoding='utf-8-sig') as f:\n",
    "    lines = [t.strip() for t in f.readlines() if t != '\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = {}\n",
    "for c in string.ascii_lowercase:\n",
    "    p0[c] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0 = {}\n",
    "for c1 in string.ascii_lowercase:\n",
    "    for c2 in string.ascii_lowercase:\n",
    "        a0[(c1,c2)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    tokens = re.sub('[^a-zA-Z ]+', '', line.replace('—',' ')).lower().split()\n",
    "    \n",
    "    for token in tokens:\n",
    "        cont = 0\n",
    "        \n",
    "        for c in range(len(token)):\n",
    "            if(cont == 0):\n",
    "                p0[token[c]] = p0.get(token[c],0) + 1\n",
    "            else:\n",
    "                a0[(token[c-1],token[c])] = a0.get((token[c-1],token[c]),0) + 1\n",
    "            cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2_prob(dict_int):\n",
    "    total = 0\n",
    "    for k,v in dict_int.items():\n",
    "        total += v\n",
    "    for k,v in dict_int.items():\n",
    "        dict_int[k] = v / total\n",
    "    \n",
    "    return dict_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [d[key] for key in d.keys() if key[0] == 'apple']\n",
    "def convert2_prob_a0(a0):\n",
    "    for c1 in string.ascii_lowercase:\n",
    "        total = sum([a0[key] for key in a0.keys() if key[0] == c1])\n",
    "\n",
    "        for c2 in string.ascii_lowercase:\n",
    "            a0[(c1,c2)] = a0[(c1,c2)] / total\n",
    "    return a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = convert2_prob(p0)\n",
    "a0 = convert2_prob_a0(a0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substitution Cipher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cipher(cipher):\n",
    "    dict_cipher = {}\n",
    "    original = list(string.ascii_lowercase)\n",
    "    \n",
    "    for c1,c2 in zip(original,cipher):\n",
    "        dict_cipher[c1] = c2\n",
    "    \n",
    "    return dict_cipher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = list(string.ascii_lowercase)\n",
    "cipher = list(string.ascii_lowercase)\n",
    "cipher = ''.join(random.sample(cipher,len(cipher)))\n",
    "\n",
    "enc_dec_cipher = {}\n",
    "\n",
    "for c1,c2 in zip(original,cipher):\n",
    "    enc_dec_cipher[c1] = c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(word,enc_dec_cipher):\n",
    "    cipher_word = ''\n",
    "    for c in word:\n",
    "        cipher_word += enc_dec_cipher[c]\n",
    "    return cipher_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_text(word,enc_dec_cipher):\n",
    "    key_list = list(enc_dec_cipher.keys())\n",
    "    val_list = list(enc_dec_cipher.values())\n",
    "    \n",
    "    cipher_word = ''\n",
    "    \n",
    "    for c in word:\n",
    "        cipher_word += key_list[val_list.index(c)]\n",
    "    return cipher_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Encode and Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bjcygwr', 'fkkiqzmn', 'bcff', 'iw', 'qnjicwf', 'nkiw', 'pwcrn', 'cmk', 'zwlwr', 'iqzx', 'jkh', 'fkzm', 'yrwbqnwfp', 'jclqzm', 'fqggfw', 'kr', 'zk', 'ikzwp', 'qz', 'ip', 'yornw', 'czx', 'zkgjqzm', 'ycrgqbofcr', 'gk', 'qzgwrwng', 'iw', 'kz', 'njkrw', 'q', 'gjkomjg', 'q', 'hkofx', 'ncqf', 'cakog', 'c', 'fqggfw', 'czx', 'nww', 'gjw', 'hcgwrp', 'ycrg', 'kv', 'gjw', 'hkrfx', 'qg', 'qn', 'c', 'hcp', 'q', 'jclw', 'kv', 'xrqlqzm', 'kvv', 'gjw', 'nyfwwz', 'czx', 'rwmofcgqzm', 'gjw', 'bqrbofcgqkz', 'hjwzwlwr', 'q', 'vqzx', 'ipnwfv', 'mrkhqzm', 'mrqi', 'cakog', 'gjw', 'ikogj', 'hjwzwlwr', 'qg', 'qn', 'c', 'xciy', 'xrqttfp', 'zklwiawr', 'qz', 'ip', 'nkof', 'hjwzwlwr', 'q', 'vqzx', 'ipnwfv', 'qzlkfozgcrqfp', 'yconqzm', 'awvkrw', 'bkvvqz', 'hcrwjkonwn', 'czx', 'arqzmqzm', 'oy', 'gjw', 'rwcr', 'kv', 'wlwrp', 'vozwrcf', 'q', 'iwwg', 'czx', 'wnywbqcffp', 'hjwzwlwr', 'ip', 'jpykn', 'mwg', 'nobj', 'cz', 'oyywr', 'jczx', 'kv', 'iw', 'gjcg', 'qg', 'rwuoqrwn', 'c', 'ngrkzm', 'ikrcf', 'yrqzbqyfw', 'gk', 'yrwlwzg', 'iw', 'vrki', 'xwfqawrcgwfp', 'ngwyyqzm', 'qzgk', 'gjw', 'ngrwwg', 'czx', 'iwgjkxqbcffp', 'dzkbdqzm', 'ywkyfwn', 'jcgn', 'kvv', 'gjwz', 'q', 'cbbkozg', 'qg', 'jqmj', 'gqiw', 'gk', 'mwg', 'gk', 'nwc', 'cn', 'nkkz', 'cn', 'q', 'bcz', 'gjqn', 'qn', 'ip', 'noangqgogw', 'vkr', 'yqngkf', 'czx', 'acff', 'hqgj', 'c', 'yjqfknkyjqbcf', 'vfkorqnj', 'bcgk', 'gjrkhn', 'jqinwfv', 'oykz', 'jqn', 'nhkrx', 'q', 'uoqwgfp', 'gcdw', 'gk', 'gjw', 'njqy', 'gjwrw', 'qn', 'zkgjqzm', 'noryrqnqzm', 'qz', 'gjqn', 'qv', 'gjwp', 'aog', 'dzwh', 'qg', 'cfikng', 'cff', 'iwz', 'qz', 'gjwqr', 'xwmrww', 'nkiw', 'gqiw', 'kr', 'kgjwr', 'bjwrqnj', 'lwrp', 'zwcrfp', 'gjw', 'nciw', 'vwwfqzmn', 'gkhcrxn', 'gjw', 'kbwcz', 'hqgj', 'iw', 'gjwrw', 'zkh', 'qn', 'pkor', 'qznofcr', 'bqgp', 'kv', 'gjw', 'iczjcggkwn', 'awfgwx', 'rkozx', 'ap', 'hjcrlwn', 'cn', 'qzxqcz', 'qnfwn', 'ap', 'bkrcf', 'rwwvn', 'bkiiwrbw', 'norrkozxn', 'qg', 'hqgj', 'jwr', 'norv', 'rqmjg', 'czx', 'fwvg', 'gjw', 'ngrwwgn', 'gcdw', 'pko', 'hcgwrhcrx', 'qgn', 'wegrwiw']\n"
     ]
    }
   ],
   "source": [
    "text_test = []\n",
    "for line in lines[:20]:\n",
    "    tokens = re.sub('[^a-zA-Z ]+', '', line.replace('—',' ')).lower().split()\n",
    "    #print(tokens)\n",
    "    text_test = [y for x in [text_test, tokens] for y in x]\n",
    "#print(text_test)\n",
    "\n",
    "text_test_enc = []\n",
    "for word in text_test:\n",
    "    word_enc = encode_text(word,enc_dec_cipher)\n",
    "    text_test_enc.append(word_enc)\n",
    "print(text_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'then', 'lounged', 'down', 'the', 'street', 'and', 'foundas', 'i', 'expected', 'that', 'there', 'was', 'a', 'mews', 'in', 'a', 'lane', 'which', 'runs', 'downby', 'one', 'wall', 'of', 'the', 'garden', 'i', 'lent', 'the', 'ostlers', 'a', 'hand', 'in', 'rubbingdown', 'their', 'horses', 'and', 'received', 'in', 'exchange', 'twopence', 'a', 'glass', 'ofhalfandhalf', 'two', 'fills', 'of', 'shag', 'tobacco', 'and', 'as', 'much', 'informationas', 'i', 'could', 'desire', 'about', 'miss', 'adler', 'to', 'say', 'nothing', 'of', 'half', 'a', 'dozenother', 'people', 'in', 'the', 'neighbourhood', 'in', 'whom', 'i', 'was', 'not', 'in', 'the', 'leastinterested', 'but', 'whose', 'biographies', 'i', 'was', 'compelled', 'to', 'listen', 'to']\n"
     ]
    }
   ],
   "source": [
    "original_message = '''I then lounged down the street and found,\n",
    "as I expected, that there was a mews in a lane which runs down\n",
    "by one wall of the garden. I lent the ostlers a hand in rubbing\n",
    "down their horses, and received in exchange twopence, a glass of\n",
    "half-and-half, two fills of shag tobacco, and as much information\n",
    "as I could desire about Miss Adler, to say nothing of half a dozen\n",
    "other people in the neighbourhood in whom I was not in the least\n",
    "interested, but whose biographies I was compelled to listen to.\n",
    "'''\n",
    "#text_test = re.sub('[^a-zA-Z ]+', '', original_message.replace('—',' ')).lower().split()\n",
    "#print(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bjcygwr\n",
      "chapter\n",
      "fkkiqzmn\n",
      "loomings\n",
      "bcff\n",
      "call\n",
      "iw\n",
      "me\n",
      "qnjicwf\n",
      "ishmael\n",
      "nkiw\n",
      "some\n",
      "pwcrn\n",
      "years\n",
      "cmk\n",
      "ago\n",
      "zwlwr\n",
      "never\n",
      "iqzx\n",
      "mind\n",
      "jkh\n",
      "how\n",
      "fkzm\n",
      "long\n",
      "yrwbqnwfp\n",
      "precisely\n",
      "jclqzm\n",
      "having\n",
      "fqggfw\n",
      "little\n",
      "kr\n",
      "or\n",
      "zk\n",
      "no\n",
      "ikzwp\n",
      "money\n",
      "qz\n",
      "in\n",
      "ip\n",
      "my\n",
      "yornw\n",
      "purse\n",
      "czx\n",
      "and\n",
      "zkgjqzm\n",
      "nothing\n",
      "ycrgqbofcr\n",
      "particular\n",
      "gk\n",
      "to\n",
      "qzgwrwng\n",
      "interest\n",
      "iw\n",
      "me\n",
      "kz\n",
      "on\n",
      "njkrw\n",
      "shore\n",
      "q\n",
      "i\n",
      "gjkomjg\n",
      "thought\n",
      "q\n",
      "i\n",
      "hkofx\n",
      "would\n",
      "ncqf\n",
      "sail\n",
      "cakog\n",
      "about\n",
      "c\n",
      "a\n",
      "fqggfw\n",
      "little\n",
      "czx\n",
      "and\n",
      "nww\n",
      "see\n",
      "gjw\n",
      "the\n",
      "hcgwrp\n",
      "watery\n",
      "ycrg\n",
      "part\n",
      "kv\n",
      "of\n",
      "gjw\n",
      "the\n",
      "hkrfx\n",
      "world\n",
      "qg\n",
      "it\n",
      "qn\n",
      "is\n",
      "c\n",
      "a\n",
      "hcp\n",
      "way\n",
      "q\n",
      "i\n",
      "jclw\n",
      "have\n",
      "kv\n",
      "of\n",
      "xrqlqzm\n",
      "driving\n",
      "kvv\n",
      "off\n",
      "gjw\n",
      "the\n",
      "nyfwwz\n",
      "spleen\n",
      "czx\n",
      "and\n",
      "rwmofcgqzm\n",
      "regulating\n",
      "gjw\n",
      "the\n",
      "bqrbofcgqkz\n",
      "circulation\n",
      "hjwzwlwr\n",
      "whenever\n",
      "q\n",
      "i\n",
      "vqzx\n",
      "find\n",
      "ipnwfv\n",
      "myself\n",
      "mrkhqzm\n",
      "growing\n",
      "mrqi\n",
      "grim\n",
      "cakog\n",
      "about\n",
      "gjw\n",
      "the\n",
      "ikogj\n",
      "mouth\n",
      "hjwzwlwr\n",
      "whenever\n",
      "qg\n",
      "it\n",
      "qn\n",
      "is\n",
      "c\n",
      "a\n",
      "xciy\n",
      "damp\n",
      "xrqttfp\n",
      "drizzly\n",
      "zklwiawr\n",
      "november\n",
      "qz\n",
      "in\n",
      "ip\n",
      "my\n",
      "nkof\n",
      "soul\n",
      "hjwzwlwr\n",
      "whenever\n",
      "q\n",
      "i\n",
      "vqzx\n",
      "find\n",
      "ipnwfv\n",
      "myself\n",
      "qzlkfozgcrqfp\n",
      "involuntarily\n",
      "yconqzm\n",
      "pausing\n",
      "awvkrw\n",
      "before\n",
      "bkvvqz\n",
      "coffin\n",
      "hcrwjkonwn\n",
      "warehouses\n",
      "czx\n",
      "and\n",
      "arqzmqzm\n",
      "bringing\n",
      "oy\n",
      "up\n",
      "gjw\n",
      "the\n",
      "rwcr\n",
      "rear\n",
      "kv\n",
      "of\n",
      "wlwrp\n",
      "every\n",
      "vozwrcf\n",
      "funeral\n",
      "q\n",
      "i\n",
      "iwwg\n",
      "meet\n",
      "czx\n",
      "and\n",
      "wnywbqcffp\n",
      "especially\n",
      "hjwzwlwr\n",
      "whenever\n",
      "ip\n",
      "my\n",
      "jpykn\n",
      "hypos\n",
      "mwg\n",
      "get\n",
      "nobj\n",
      "such\n",
      "cz\n",
      "an\n",
      "oyywr\n",
      "upper\n",
      "jczx\n",
      "hand\n",
      "kv\n",
      "of\n",
      "iw\n",
      "me\n",
      "gjcg\n",
      "that\n",
      "qg\n",
      "it\n",
      "rwuoqrwn\n",
      "requires\n",
      "c\n",
      "a\n",
      "ngrkzm\n",
      "strong\n",
      "ikrcf\n",
      "moral\n",
      "yrqzbqyfw\n",
      "principle\n",
      "gk\n",
      "to\n",
      "yrwlwzg\n",
      "prevent\n",
      "iw\n",
      "me\n",
      "vrki\n",
      "from\n",
      "xwfqawrcgwfp\n",
      "deliberately\n",
      "ngwyyqzm\n",
      "stepping\n",
      "qzgk\n",
      "into\n",
      "gjw\n",
      "the\n",
      "ngrwwg\n",
      "street\n",
      "czx\n",
      "and\n",
      "iwgjkxqbcffp\n",
      "methodically\n",
      "dzkbdqzm\n",
      "knocking\n",
      "ywkyfwn\n",
      "peoples\n",
      "jcgn\n",
      "hats\n",
      "kvv\n",
      "off\n",
      "gjwz\n",
      "then\n",
      "q\n",
      "i\n",
      "cbbkozg\n",
      "account\n",
      "qg\n",
      "it\n",
      "jqmj\n",
      "high\n",
      "gqiw\n",
      "time\n",
      "gk\n",
      "to\n",
      "mwg\n",
      "get\n",
      "gk\n",
      "to\n",
      "nwc\n",
      "sea\n",
      "cn\n",
      "as\n",
      "nkkz\n",
      "soon\n",
      "cn\n",
      "as\n",
      "q\n",
      "i\n",
      "bcz\n",
      "can\n",
      "gjqn\n",
      "this\n",
      "qn\n",
      "is\n",
      "ip\n",
      "my\n",
      "noangqgogw\n",
      "substitute\n",
      "vkr\n",
      "for\n",
      "yqngkf\n",
      "pistol\n",
      "czx\n",
      "and\n",
      "acff\n",
      "ball\n",
      "hqgj\n",
      "with\n",
      "c\n",
      "a\n",
      "yjqfknkyjqbcf\n",
      "philosophical\n",
      "vfkorqnj\n",
      "flourish\n",
      "bcgk\n",
      "cato\n",
      "gjrkhn\n",
      "throws\n",
      "jqinwfv\n",
      "himself\n",
      "oykz\n",
      "upon\n",
      "jqn\n",
      "his\n",
      "nhkrx\n",
      "sword\n",
      "q\n",
      "i\n",
      "uoqwgfp\n",
      "quietly\n",
      "gcdw\n",
      "take\n",
      "gk\n",
      "to\n",
      "gjw\n",
      "the\n",
      "njqy\n",
      "ship\n",
      "gjwrw\n",
      "there\n",
      "qn\n",
      "is\n",
      "zkgjqzm\n",
      "nothing\n",
      "noryrqnqzm\n",
      "surprising\n",
      "qz\n",
      "in\n",
      "gjqn\n",
      "this\n",
      "qv\n",
      "if\n",
      "gjwp\n",
      "they\n",
      "aog\n",
      "but\n",
      "dzwh\n",
      "knew\n",
      "qg\n",
      "it\n",
      "cfikng\n",
      "almost\n",
      "cff\n",
      "all\n",
      "iwz\n",
      "men\n",
      "qz\n",
      "in\n",
      "gjwqr\n",
      "their\n",
      "xwmrww\n",
      "degree\n",
      "nkiw\n",
      "some\n",
      "gqiw\n",
      "time\n",
      "kr\n",
      "or\n",
      "kgjwr\n",
      "other\n",
      "bjwrqnj\n",
      "cherish\n",
      "lwrp\n",
      "very\n",
      "zwcrfp\n",
      "nearly\n",
      "gjw\n",
      "the\n",
      "nciw\n",
      "same\n",
      "vwwfqzmn\n",
      "feelings\n",
      "gkhcrxn\n",
      "towards\n",
      "gjw\n",
      "the\n",
      "kbwcz\n",
      "ocean\n",
      "hqgj\n",
      "with\n",
      "iw\n",
      "me\n",
      "gjwrw\n",
      "there\n",
      "zkh\n",
      "now\n",
      "qn\n",
      "is\n",
      "pkor\n",
      "your\n",
      "qznofcr\n",
      "insular\n",
      "bqgp\n",
      "city\n",
      "kv\n",
      "of\n",
      "gjw\n",
      "the\n",
      "iczjcggkwn\n",
      "manhattoes\n",
      "awfgwx\n",
      "belted\n",
      "rkozx\n",
      "round\n",
      "ap\n",
      "by\n",
      "hjcrlwn\n",
      "wharves\n",
      "cn\n",
      "as\n",
      "qzxqcz\n",
      "indian\n",
      "qnfwn\n",
      "isles\n",
      "ap\n",
      "by\n",
      "bkrcf\n",
      "coral\n",
      "rwwvn\n",
      "reefs\n",
      "bkiiwrbw\n",
      "commerce\n",
      "norrkozxn\n",
      "surrounds\n",
      "qg\n",
      "it\n",
      "hqgj\n",
      "with\n",
      "jwr\n",
      "her\n",
      "norv\n",
      "surf\n",
      "rqmjg\n",
      "right\n",
      "czx\n",
      "and\n",
      "fwvg\n",
      "left\n",
      "gjw\n",
      "the\n",
      "ngrwwgn\n",
      "streets\n",
      "gcdw\n",
      "take\n",
      "pko\n",
      "you\n",
      "hcgwrhcrx\n",
      "waterward\n",
      "qgn\n",
      "its\n",
      "wegrwiw\n",
      "extreme\n"
     ]
    }
   ],
   "source": [
    "for word in text_test:\n",
    "    nw = encode_text(word,enc_dec_cipher)\n",
    "    print(nw)\n",
    "    nw = decode_text(nw,enc_dec_cipher)\n",
    "    print(nw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population inicialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"population_size = 10\\n\\npopulation = []\\n\\nfor i in range(population_size):\\n    population.append(list(''.join(random.sample(original,len(original)))))\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''population_size = 10\n",
    "\n",
    "population = []\n",
    "\n",
    "for i in range(population_size):\n",
    "    population.append(list(''.join(random.sample(original,len(original)))))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avaliation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliate_cipher(ind,text_test):\n",
    "    dict_cipher = create_cipher(ind)\n",
    "    total_prob = 0\n",
    "    \n",
    "    for word in text_test:\n",
    "        decoded_word = decode_text(word,dict_cipher)\n",
    "        \n",
    "        cont = 0\n",
    "        for i in range(len(decoded_word)):\n",
    "            if(i == 0):\n",
    "                total_prob += np.log(p0[decoded_word[i]])\n",
    "            else:\n",
    "                total_prob += np.log(a0[(decoded_word[i-1],decoded_word[i])])\n",
    "    return total_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'avaliations = []\\nfor ind in range(population_size):\\n    aval = avaliate_cipher(population[ind],text_test)\\n    avaliations.append(aval)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''avaliations = []\n",
    "for ind in range(population_size):\n",
    "    aval = avaliate_cipher(population[ind],text_test)\n",
    "    avaliations.append(aval)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parents Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_parent(avaliations):\n",
    "    max_value = sum(avaliations)\n",
    "    \n",
    "    rand_parent = random.uniform(0, max_value)\n",
    "    \n",
    "    start_interv = 0\n",
    "    end_interv = 0\n",
    "    for c_aval in range(len(avaliations)):\n",
    "        if(c_aval == 0):\n",
    "            end_interv = avaliations[c_aval]\n",
    "        else:\n",
    "            start_interv = end_interv\n",
    "            end_interv = end_interv + avaliations[c_aval]\n",
    "            \n",
    "        if(start_interv <= rand_parent  and rand_parent < end_interv):\n",
    "            return c_aval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'selected_parents = []\\n\\nfor i in range(population_size):\\n    parent = select_parent(avaliations)\\n    selected_parents.append(parent)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''selected_parents = []\n",
    "\n",
    "for i in range(population_size):\n",
    "    parent = select_parent(avaliations)\n",
    "    selected_parents.append(parent)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_parents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(n_kid=3):\n",
    "    offspring = []\n",
    "\n",
    "    for i in range(len(population)):\n",
    "        for _ in range(n_kid):\n",
    "            kid = population[i].copy()\n",
    "            j = np.random.randint(len(kid))\n",
    "            k = 0\n",
    "\n",
    "            while True:\n",
    "                k = np.random.randint(len(kid))\n",
    "                if(j != k):\n",
    "                    break\n",
    "\n",
    "            #print(j,k)\n",
    "            temp = kid[k]\n",
    "            kid[k] = kid[j]\n",
    "            kid[j] = temp\n",
    "\n",
    "            offspring.append(kid)\n",
    "    \n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offspring = mutation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new_avaliations = []\\nfor ind in range(len(offspring)):\\n    aval = avaliate_cipher(offspring[ind],text_test)\\n    new_avaliations.append(aval)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''new_avaliations = []\n",
    "for ind in range(len(offspring)):\n",
    "    aval = avaliate_cipher(offspring[ind],text_test)\n",
    "    new_avaliations.append(aval)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(new_avaliations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avaliations = avaliations + new_avaliations\n",
    "#population = population + offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(avaliations),np.max(avaliations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(np.argpartition(avaliations, -4)[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -5597.236854779519 -4908.821697895854\n",
      "ntcwzlejkusrqihpdoyfagvmbx\n",
      "10 -4063.8687682326017 -3785.956341457486\n",
      "qbvrwhusoefcylkntgzjxapdim\n",
      "20 -3783.9841234331957 -3555.970018087819\n",
      "qbvzwhumxeicylkntgrfoapdjs\n",
      "30 -3517.1854369336015 -3306.4456762577915\n",
      "qivawhfmcelxnrkysjzgoubdpt\n",
      "40 -3444.637878690065 -3190.5085140710153\n",
      "qihnwvamcdlfxrkysjzgoubept\n",
      "50 -3303.536443825328 -3028.046570757889\n",
      "qimbwapjcdlnxfkyurzgoshevt\n",
      "60 -3173.6559345408114 -2797.332487296214\n",
      "qimbwdxjclafvzkytrngouheps\n",
      "70 -3060.5930426249192 -2763.8724594584146\n",
      "qibmwdxjclafvzkysrngouhept\n",
      "80 -2997.0486452467594 -2713.6870510978897\n",
      "cimxwabjqtdfvzkyerngouhspl\n",
      "90 -2973.1351359650916 -2645.902239249364\n",
      "cimxwabjqedfvzkyurngolhspt\n",
      "100 -2881.8491286292156 -2601.4094594831186\n",
      "cibxwamjqtdfvzkyurngolheps\n",
      "110 -2882.814304836361 -2594.4494078976395\n",
      "cabxwvmjqtdfizkyurngoehspl\n",
      "120 -2851.510239061775 -2579.768745834876\n",
      "cibxwvmjqtdfazkyurngolhspe\n",
      "130 -2880.5446416794775 -2545.507938466622\n",
      "cabxwvmjqtdfizkyurngolhspe\n",
      "140 -2809.090394225119 -2545.507938466622\n",
      "cabxwvmjqtdfizkyurngolhspe\n",
      "150 -2841.8419838737695 -2533.27059701414\n",
      "cabxwvmjqudfizkysrngolhept\n",
      "160 -2867.1823613869146 -2533.27059701414\n",
      "cabxwvmjqudfizkysrngolhept\n",
      "170 -2800.528715937564 -2527.606050176361\n",
      "cabxwvmjqsdfizkyurngolhept\n",
      "180 -2811.5354320661754 -2527.606050176361\n",
      "cabxwvmjqsdfizkyurngolhept\n",
      "190 -2799.105536752295 -2527.606050176361\n",
      "cabxwvmjqsdfizkyurngolhept\n",
      "-2527.606050176361\n",
      "26 0\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "\n",
    "\n",
    "population_size = 20\n",
    "portion = 5\n",
    "n_kid = 4\n",
    "population = []\n",
    "\n",
    "for i in range(population_size):\n",
    "    population.append(list(''.join(random.sample(original,len(original)))))\n",
    "    \n",
    "avaliations = []\n",
    "for ind in range(population_size):\n",
    "    aval = avaliate_cipher(population[ind],text_test_enc)\n",
    "    avaliations.append(aval)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    offspring = mutation(n_kid)\n",
    "    \n",
    "    new_avaliations = []\n",
    "    for ind in range(len(offspring)):\n",
    "        aval = avaliate_cipher(offspring[ind],text_test_enc)\n",
    "        new_avaliations.append(aval)\n",
    "        \n",
    "    avaliations = avaliations + new_avaliations\n",
    "    population = population + offspring\n",
    "    \n",
    "    if(epoch % 10 == 0):\n",
    "        print(epoch,np.mean(avaliations),np.max(avaliations))\n",
    "        best_index = list(np.argpartition(avaliations, -1)[-1:])[0]\n",
    "        print(''.join(population[best_index]))\n",
    "        \n",
    "    indexes = list(np.argpartition(avaliations, -population_size)[-population_size:])\n",
    "    \n",
    "    new_population = []\n",
    "    new_avals = []\n",
    "    for i in indexes:\n",
    "        new_population.append(population[i])\n",
    "        new_avals.append(avaliations[i])\n",
    "        \n",
    "    population = new_population\n",
    "    avaliations = new_avals\n",
    "\n",
    "best_index = list(np.argpartition(avaliations, -1)[-1:])[0]\n",
    "print(avaliations[best_index])\n",
    "\n",
    "count_yes = 0\n",
    "count_no = 0\n",
    "\n",
    "for c1,c2 in zip(''.join(population[best_index]),cipher):\n",
    "    #print(c1,c2)\n",
    "    if(c1 == c2):\n",
    "        count_yes += 1\n",
    "    else:\n",
    "        count_no += 1\n",
    "print(count_yes,count_no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cabxwvmjqsdfizkyurngolhept'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cipher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 'c', 'b': 'a', 'c': 'b', 'd': 'x', 'e': 'w', 'f': 'v', 'g': 'm', 'h': 'j', 'i': 'q', 'j': 's', 'k': 'd', 'l': 'f', 'm': 'i', 'n': 'z', 'o': 'k', 'p': 'y', 'q': 'u', 'r': 'r', 's': 'n', 't': 'g', 'u': 'o', 'v': 'l', 'w': 'h', 'x': 'e', 'y': 'p', 'z': 't'}\n"
     ]
    }
   ],
   "source": [
    "best_cipher = {}\n",
    "for c1,c2 in zip(list(string.ascii_lowercase),''.join(population[best_index])):\n",
    "    best_cipher[c1] = c2\n",
    "print(best_cipher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chapter', 'loomings', 'call', 'me', 'ishmael', 'some', 'years', 'ago', 'never', 'mind', 'how', 'long', 'precisely', 'having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', 'i', 'thought', 'i', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world', 'it', 'is', 'a', 'way', 'i', 'have', 'of', 'driving', 'off', 'the', 'spleen', 'and', 'regulating', 'the', 'circulation', 'whenever', 'i', 'find', 'myself', 'growing', 'grim', 'about', 'the', 'mouth', 'whenever', 'it', 'is', 'a', 'damp', 'drizzly', 'november', 'in', 'my', 'soul', 'whenever', 'i', 'find', 'myself', 'involuntarily', 'pausing', 'before', 'coffin', 'warehouses', 'and', 'bringing', 'up', 'the', 'rear', 'of', 'every', 'funeral', 'i', 'meet', 'and', 'especially', 'whenever', 'my', 'hypos', 'get', 'such', 'an', 'upper', 'hand', 'of', 'me', 'that', 'it', 'requires', 'a', 'strong', 'moral', 'principle', 'to', 'prevent', 'me', 'from', 'deliberately', 'stepping', 'into', 'the', 'street', 'and', 'methodically', 'knocking', 'peoples', 'hats', 'off', 'then', 'i', 'account', 'it', 'high', 'time', 'to', 'get', 'to', 'sea', 'as', 'soon', 'as', 'i', 'can', 'this', 'is', 'my', 'substitute', 'for', 'pistol', 'and', 'ball', 'with', 'a', 'philosophical', 'flourish', 'cato', 'throws', 'himself', 'upon', 'his', 'sword', 'i', 'quietly', 'take', 'to', 'the', 'ship', 'there', 'is', 'nothing', 'surprising', 'in', 'this', 'if', 'they', 'but', 'knew', 'it', 'almost', 'all', 'men', 'in', 'their', 'degree', 'some', 'time', 'or', 'other', 'cherish', 'very', 'nearly', 'the', 'same', 'feelings', 'towards', 'the', 'ocean', 'with', 'me', 'there', 'now', 'is', 'your', 'insular', 'city', 'of', 'the', 'manhattoes', 'belted', 'round', 'by', 'wharves', 'as', 'indian', 'isles', 'by', 'coral', 'reefs', 'commerce', 'surrounds', 'it', 'with', 'her', 'surf', 'right', 'and', 'left', 'the', 'streets', 'take', 'you', 'waterward', 'its', 'extreme']\n"
     ]
    }
   ],
   "source": [
    "text_test_dec = []\n",
    "for word in text_test_enc:\n",
    "    word_dec = decode_text(word,best_cipher)\n",
    "    text_test_dec.append(word_dec)\n",
    "\n",
    "print(text_test_dec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
