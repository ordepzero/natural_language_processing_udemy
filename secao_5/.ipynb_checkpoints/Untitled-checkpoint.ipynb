{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a markov model based on an English dataset\n",
    "# is an edit of https://www.gutenberg.org/ebooks/2701\n",
    "# (I removed the front and back matter)\n",
    "\n",
    "# download the file\n",
    "if not os.path.exists('moby_dick.txt'):\n",
    "    print(\"Downloading moby dick...\")\n",
    "    r = requests.get('https://lazyprogrammer.me/course_files/moby_dick.txt')\n",
    "    with open('moby_dick.txt', 'w',encoding='utf-8') as f:\n",
    "        f.write(r.content.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('moby_dick.txt',encoding='utf-8-sig') as f:\n",
    "    lines = [t.strip() for t in f.readlines() if t != '\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = {}\n",
    "for c in string.ascii_lowercase:\n",
    "    p0[c] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a0 = {}\n",
    "for c1 in string.ascii_lowercase:\n",
    "    for c2 in string.ascii_lowercase:\n",
    "        a0[(c1,c2)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    tokens = re.sub('[^a-zA-Z ]+', '', line.replace('—',' ')).lower().split()\n",
    "    \n",
    "    for token in tokens:\n",
    "        cont = 0\n",
    "        \n",
    "        for c in range(len(token)):\n",
    "            if(cont == 0):\n",
    "                p0[token[c]] = p0.get(token[c],0) + 1\n",
    "            else:\n",
    "                a0[(token[c-1],token[c])] = a0.get((token[c-1],token[c]),0) + 1\n",
    "            cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2_prob(dict_int):\n",
    "    total = 0\n",
    "    for k,v in dict_int.items():\n",
    "        total += v\n",
    "    for k,v in dict_int.items():\n",
    "        dict_int[k] = v / total\n",
    "    \n",
    "    return dict_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [d[key] for key in d.keys() if key[0] == 'apple']\n",
    "def convert2_prob_a0(a0):\n",
    "    for c1 in string.ascii_lowercase:\n",
    "        total = sum([a0[key] for key in a0.keys() if key[0] == c1])\n",
    "\n",
    "        for c2 in string.ascii_lowercase:\n",
    "            a0[(c1,c2)] = a0[(c1,c2)] / total\n",
    "    return a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = convert2_prob(p0)\n",
    "a0 = convert2_prob_a0(a0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Substitution Cipher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cipher(cipher):\n",
    "    dict_cipher = {}\n",
    "    original = list(string.ascii_lowercase)\n",
    "    \n",
    "    for c1,c2 in zip(original,cipher):\n",
    "        dict_cipher[c1] = c2\n",
    "    \n",
    "    return dict_cipher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = list(string.ascii_lowercase)\n",
    "cipher = list(string.ascii_lowercase)\n",
    "cipher = ''.join(random.sample(cipher,len(cipher)))\n",
    "\n",
    "enc_dec_cipher = {}\n",
    "\n",
    "for c1,c2 in zip(original,cipher):\n",
    "    enc_dec_cipher[c1] = c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(word,enc_dec_cipher):\n",
    "    cipher_word = ''\n",
    "    for c in word:\n",
    "        cipher_word += enc_dec_cipher[c]\n",
    "    return cipher_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_text(word,enc_dec_cipher):\n",
    "    key_list = list(enc_dec_cipher.keys())\n",
    "    val_list = list(enc_dec_cipher.values())\n",
    "    \n",
    "    cipher_word = ''\n",
    "    \n",
    "    for c in word:\n",
    "        cipher_word += key_list[val_list.index(c)]\n",
    "    return cipher_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Encode and Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chapter', 'loomings', 'call', 'me', 'ishmael', 'some', 'years', 'ago', 'never', 'mind', 'how', 'long', 'precisely', 'having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', 'i', 'thought', 'i', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world', 'it', 'is', 'a', 'way', 'i', 'have', 'of', 'driving', 'off', 'the', 'spleen', 'and', 'regulating', 'the', 'circulation', 'whenever', 'i', 'find', 'myself', 'growing', 'grim', 'about', 'the', 'mouth', 'whenever', 'it', 'is', 'a', 'damp', 'drizzly', 'november', 'in', 'my', 'soul', 'whenever', 'i', 'find', 'myself', 'involuntarily', 'pausing', 'before', 'coffin', 'warehouses', 'and', 'bringing', 'up', 'the', 'rear', 'of', 'every', 'funeral', 'i', 'meet', 'and', 'especially', 'whenever', 'my', 'hypos', 'get', 'such', 'an', 'upper', 'hand', 'of', 'me', 'that', 'it', 'requires', 'a', 'strong', 'moral']\n"
     ]
    }
   ],
   "source": [
    "text_test = []\n",
    "for line in lines[:10]:\n",
    "    tokens = re.sub('[^a-zA-Z ]+', '', line.replace('—',' ')).lower().split()\n",
    "    #print(tokens)\n",
    "    text_test = [y for x in [text_test, tokens] for y in x]\n",
    "print(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'then', 'lounged', 'down', 'the', 'street', 'and', 'foundas', 'i', 'expected', 'that', 'there', 'was', 'a', 'mews', 'in', 'a', 'lane', 'which', 'runs', 'downby', 'one', 'wall', 'of', 'the', 'garden', 'i', 'lent', 'the', 'ostlers', 'a', 'hand', 'in', 'rubbingdown', 'their', 'horses', 'and', 'received', 'in', 'exchange', 'twopence', 'a', 'glass', 'ofhalfandhalf', 'two', 'fills', 'of', 'shag', 'tobacco', 'and', 'as', 'much', 'informationas', 'i', 'could', 'desire', 'about', 'miss', 'adler', 'to', 'say', 'nothing', 'of', 'half', 'a', 'dozenother', 'people', 'in', 'the', 'neighbourhood', 'in', 'whom', 'i', 'was', 'not', 'in', 'the', 'leastinterested', 'but', 'whose', 'biographies', 'i', 'was', 'compelled', 'to', 'listen', 'to']\n"
     ]
    }
   ],
   "source": [
    "original_message = '''I then lounged down the street and found,\n",
    "as I expected, that there was a mews in a lane which runs down\n",
    "by one wall of the garden. I lent the ostlers a hand in rubbing\n",
    "down their horses, and received in exchange twopence, a glass of\n",
    "half-and-half, two fills of shag tobacco, and as much information\n",
    "as I could desire about Miss Adler, to say nothing of half a dozen\n",
    "other people in the neighbourhood in whom I was not in the least\n",
    "interested, but whose biographies I was compelled to listen to.\n",
    "'''\n",
    "text_test = re.sub('[^a-zA-Z ]+', '', original_message.replace('—',' ')).lower().split()\n",
    "print(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ufdhrjz\n",
      "chapter\n",
      "awwcvymn\n",
      "loomings\n",
      "udaa\n",
      "call\n",
      "cj\n",
      "me\n",
      "vnfcdja\n",
      "ishmael\n",
      "nwcj\n",
      "some\n",
      "ojdzn\n",
      "years\n",
      "dmw\n",
      "ago\n",
      "yjsjz\n",
      "never\n",
      "cvyl\n",
      "mind\n",
      "fwe\n",
      "how\n",
      "awym\n",
      "long\n",
      "hzjuvnjao\n",
      "precisely\n",
      "fdsvym\n",
      "having\n",
      "avrraj\n",
      "little\n",
      "wz\n",
      "or\n",
      "yw\n",
      "no\n",
      "cwyjo\n",
      "money\n",
      "vy\n",
      "in\n",
      "co\n",
      "my\n",
      "hiznj\n",
      "purse\n",
      "dyl\n",
      "and\n",
      "ywrfvym\n",
      "nothing\n",
      "hdzrvuiadz\n",
      "particular\n",
      "rw\n",
      "to\n",
      "vyrjzjnr\n",
      "interest\n",
      "cj\n",
      "me\n",
      "wy\n",
      "on\n",
      "nfwzj\n",
      "shore\n",
      "v\n",
      "i\n",
      "rfwimfr\n",
      "thought\n",
      "v\n",
      "i\n",
      "ewial\n",
      "would\n",
      "ndva\n",
      "sail\n",
      "dtwir\n",
      "about\n",
      "d\n",
      "a\n",
      "avrraj\n",
      "little\n",
      "dyl\n",
      "and\n",
      "njj\n",
      "see\n",
      "rfj\n",
      "the\n",
      "edrjzo\n",
      "watery\n",
      "hdzr\n",
      "part\n",
      "wk\n",
      "of\n",
      "rfj\n",
      "the\n",
      "ewzal\n",
      "world\n",
      "vr\n",
      "it\n",
      "vn\n",
      "is\n",
      "d\n",
      "a\n",
      "edo\n",
      "way\n",
      "v\n",
      "i\n",
      "fdsj\n",
      "have\n",
      "wk\n",
      "of\n",
      "lzvsvym\n",
      "driving\n",
      "wkk\n",
      "off\n",
      "rfj\n",
      "the\n",
      "nhajjy\n",
      "spleen\n",
      "dyl\n",
      "and\n",
      "zjmiadrvym\n",
      "regulating\n",
      "rfj\n",
      "the\n",
      "uvzuiadrvwy\n",
      "circulation\n",
      "efjyjsjz\n",
      "whenever\n",
      "v\n",
      "i\n",
      "kvyl\n",
      "find\n",
      "conjak\n",
      "myself\n",
      "mzwevym\n",
      "growing\n",
      "mzvc\n",
      "grim\n",
      "dtwir\n",
      "about\n",
      "rfj\n",
      "the\n",
      "cwirf\n",
      "mouth\n",
      "efjyjsjz\n",
      "whenever\n",
      "vr\n",
      "it\n",
      "vn\n",
      "is\n",
      "d\n",
      "a\n",
      "ldch\n",
      "damp\n",
      "lzvqqao\n",
      "drizzly\n",
      "ywsjctjz\n",
      "november\n",
      "vy\n",
      "in\n",
      "co\n",
      "my\n",
      "nwia\n",
      "soul\n",
      "efjyjsjz\n",
      "whenever\n",
      "v\n",
      "i\n",
      "kvyl\n",
      "find\n",
      "conjak\n",
      "myself\n",
      "vyswaiyrdzvao\n",
      "involuntarily\n",
      "hdinvym\n",
      "pausing\n",
      "tjkwzj\n",
      "before\n",
      "uwkkvy\n",
      "coffin\n",
      "edzjfwinjn\n",
      "warehouses\n",
      "dyl\n",
      "and\n",
      "tzvymvym\n",
      "bringing\n",
      "ih\n",
      "up\n",
      "rfj\n",
      "the\n",
      "zjdz\n",
      "rear\n",
      "wk\n",
      "of\n",
      "jsjzo\n",
      "every\n",
      "kiyjzda\n",
      "funeral\n",
      "v\n",
      "i\n",
      "cjjr\n",
      "meet\n",
      "dyl\n",
      "and\n",
      "jnhjuvdaao\n",
      "especially\n",
      "efjyjsjz\n",
      "whenever\n",
      "co\n",
      "my\n",
      "fohwn\n",
      "hypos\n",
      "mjr\n",
      "get\n",
      "niuf\n",
      "such\n",
      "dy\n",
      "an\n",
      "ihhjz\n",
      "upper\n",
      "fdyl\n",
      "hand\n",
      "wk\n",
      "of\n",
      "cj\n",
      "me\n",
      "rfdr\n",
      "that\n",
      "vr\n",
      "it\n",
      "zjpivzjn\n",
      "requires\n",
      "d\n",
      "a\n",
      "nrzwym\n",
      "strong\n",
      "cwzda\n",
      "moral\n"
     ]
    }
   ],
   "source": [
    "for word in text_test:\n",
    "    nw = encode_text(word,enc_dec_cipher)\n",
    "    print(nw)\n",
    "    nw = decode_text(nw,enc_dec_cipher)\n",
    "    print(nw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population inicialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"population_size = 10\\n\\npopulation = []\\n\\nfor i in range(population_size):\\n    population.append(list(''.join(random.sample(original,len(original)))))\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''population_size = 10\n",
    "\n",
    "population = []\n",
    "\n",
    "for i in range(population_size):\n",
    "    population.append(list(''.join(random.sample(original,len(original)))))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avaliation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliate_cipher(ind,text_test):\n",
    "    dict_cipher = create_cipher(ind)\n",
    "    total_prob = 0\n",
    "    \n",
    "    for word in text_test:\n",
    "        decoded_word = decode_text(word,dict_cipher)\n",
    "        \n",
    "        cont = 0\n",
    "        for i in range(len(decoded_word)):\n",
    "            if(i == 0):\n",
    "                total_prob += np.log(p0[decoded_word[i]])\n",
    "            else:\n",
    "                total_prob += np.log(a0[(decoded_word[i-1],decoded_word[i])])\n",
    "    return total_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'avaliations = []\\nfor ind in range(population_size):\\n    aval = avaliate_cipher(population[ind],text_test)\\n    avaliations.append(aval)'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''avaliations = []\n",
    "for ind in range(population_size):\n",
    "    aval = avaliate_cipher(population[ind],text_test)\n",
    "    avaliations.append(aval)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parents Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_parent(avaliations):\n",
    "    max_value = sum(avaliations)\n",
    "    \n",
    "    rand_parent = random.uniform(0, max_value)\n",
    "    \n",
    "    start_interv = 0\n",
    "    end_interv = 0\n",
    "    for c_aval in range(len(avaliations)):\n",
    "        if(c_aval == 0):\n",
    "            end_interv = avaliations[c_aval]\n",
    "        else:\n",
    "            start_interv = end_interv\n",
    "            end_interv = end_interv + avaliations[c_aval]\n",
    "            \n",
    "        if(start_interv <= rand_parent  and rand_parent < end_interv):\n",
    "            return c_aval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'selected_parents = []\\n\\nfor i in range(population_size):\\n    parent = select_parent(avaliations)\\n    selected_parents.append(parent)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''selected_parents = []\n",
    "\n",
    "for i in range(population_size):\n",
    "    parent = select_parent(avaliations)\n",
    "    selected_parents.append(parent)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_parents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(n_kid=3):\n",
    "    offspring = []\n",
    "\n",
    "    for i in range(len(population)):\n",
    "        for _ in range(n_kid):\n",
    "            kid = population[i].copy()\n",
    "            j = np.random.randint(len(kid))\n",
    "            k = 0\n",
    "\n",
    "            while True:\n",
    "                k = np.random.randint(len(kid))\n",
    "                if(j != k):\n",
    "                    break\n",
    "\n",
    "            #print(j,k)\n",
    "            temp = kid[k]\n",
    "            kid[k] = kid[j]\n",
    "            kid[j] = temp\n",
    "\n",
    "            offspring.append(kid)\n",
    "    \n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offspring = mutation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new_avaliations = []\\nfor ind in range(len(offspring)):\\n    aval = avaliate_cipher(offspring[ind],text_test)\\n    new_avaliations.append(aval)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''new_avaliations = []\n",
    "for ind in range(len(offspring)):\n",
    "    aval = avaliate_cipher(offspring[ind],text_test)\n",
    "    new_avaliations.append(aval)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(new_avaliations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avaliations = avaliations + new_avaliations\n",
    "#population = population + offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(avaliations),np.max(avaliations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(np.argpartition(avaliations, -4)[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -2081.13636065132 -1724.0756930016787\n",
      "200 -1031.7750422830325 -944.8514302567891\n",
      "400 -1041.1242315421325 -944.8514302567891\n",
      "600 -1046.1691319176218 -944.8514302567891\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-4782d69eaf73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mnew_avaliations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffspring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0maval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavaliate_cipher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffspring\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mnew_avaliations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-af0b603a1ce6>\u001b[0m in \u001b[0;36mavaliate_cipher\u001b[1;34m(ind, text_test)\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0mtotal_prob\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdecoded_word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                 \u001b[0mtotal_prob\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoded_word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoded_word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtotal_prob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "\n",
    "population_size = 20\n",
    "portion = 5\n",
    "n_kid = 4\n",
    "population = []\n",
    "\n",
    "for i in range(population_size):\n",
    "    population.append(list(''.join(random.sample(original,len(original)))))\n",
    "    \n",
    "avaliations = []\n",
    "for ind in range(population_size):\n",
    "    aval = avaliate_cipher(population[ind],text_test)\n",
    "    avaliations.append(aval)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    offspring = mutation(n_kid)\n",
    "    \n",
    "    new_avaliations = []\n",
    "    for ind in range(len(offspring)):\n",
    "        aval = avaliate_cipher(offspring[ind],text_test)\n",
    "        new_avaliations.append(aval)\n",
    "        \n",
    "    avaliations = avaliations + new_avaliations\n",
    "    population = population + offspring\n",
    "    \n",
    "    if(epoch % 200 == 0):\n",
    "        print(epoch,np.mean(avaliations),np.max(avaliations))\n",
    "        \n",
    "    indexes = list(np.argpartition(avaliations, -population_size)[-population_size:])\n",
    "    \n",
    "    new_population = []\n",
    "    new_avals = []\n",
    "    for i in indexes:\n",
    "        new_population.append(population[i])\n",
    "        new_avals.append(avaliations[i])\n",
    "        \n",
    "    population = new_population\n",
    "    avaliations = new_avals\n",
    "\n",
    "best_index = list(np.argpartition(avaliations, -1)[-1:])[0]\n",
    "print(avaliations[best_index])\n",
    "\n",
    "count_yes = 0\n",
    "count_no = 0\n",
    "\n",
    "for c1,c2 in zip(''.join(population[best_index]),cipher):\n",
    "    #print(c1,c2)\n",
    "    if(c1 == c2):\n",
    "        count_yes += 1\n",
    "    else:\n",
    "        count_no += 1\n",
    "print(count_yes,count_no)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
